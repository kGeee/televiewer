# Phase 05, Plan 01: Parquet Write Infrastructure

---

## Plan Metadata

```yaml
phase: 5
plan: 05-01
wave: 1
depends_on: []
autonomous: true
files_modified:
  - package.json
  - src/lib/server/telemetry/parquet.ts
  - src/lib/server/telemetry/types.ts
  - src/lib/server/db/utils.ts
  - src/routes/api/sessions/save/+server.ts
estimated_context: 25%
```

## must_haves

```yaml
truths:
  - 'New telemetry imports write Parquet files to disk (one file per session)'
  - 'Parquet files store telemetry channels as columns with proper types'
  - 'All existing write paths use the new Parquet storage module'
  - 'File size is 50%+ smaller than equivalent JSON array storage'

artifacts:
  - path: 'src/lib/server/telemetry/parquet.ts'
    provides: 'Parquet write/read utilities with apache-arrow'
    min_lines: 150
  - path: 'src/lib/server/telemetry/types.ts'
    provides: 'TypeScript types for telemetry storage abstraction'
    min_lines: 50
  - path: 'data/telemetry/{sessionId}.parquet'
    provides: 'Per-session Parquet telemetry files'
    min_lines: 0

key_links:
  - from: 'src/lib/server/db/utils.ts:insertSessionData()'
    to: 'src/lib/server/telemetry/parquet.ts:writeSessionTelemetry()'
    via: 'function call replacing DB insert'
  - from: 'src/routes/api/sessions/save/+server.ts'
    to: 'src/lib/server/telemetry/parquet.ts'
    via: 'import and call write function'
```

---

## Objective

Establish the Parquet file storage infrastructure for telemetry data. Create a write module that stores telemetry as columnar Parquet files on disk, replacing the current PostgreSQL array column storage. Update all write paths to use the new storage system.

---

## Task 1: Add Apache Arrow Dependency

**Type:** auto

**Files:** `package.json`

**Action:**
Add `apache-arrow` npm package as a dependency. This library provides native Parquet read/write capabilities for Node.js with full TypeScript support.

```bash
npm install apache-arrow
```

**Verify:**

```bash
grep -q "apache-arrow" package.json && echo "✓ apache-arrow installed"
npm list apache-arrow 2>/dev/null | grep -q apache-arrow && echo "✓ Package resolved"
```

**Done:**

- [ ] `apache-arrow` appears in `dependencies` in package.json
- [ ] `npm install` completes without errors
- [ ] TypeScript can import from `'apache-arrow'`

---

## Task 2: Create Telemetry Storage Types

**Type:** auto

**Files:** `src/lib/server/telemetry/types.ts`

**Action:**
Create TypeScript types defining the telemetry storage abstraction layer. These types provide a clean interface between the application and the underlying storage format.

**Type Definitions:**

```typescript
// Telemetry channel names (standard + auxiliary)
export type StandardChannel =
	| 'time'
	| 'distance'
	| 'lat'
	| 'long'
	| 'speed'
	| 'rpm'
	| 'throttle'
	| 'brake'
	| 'gear'
	| 'steering'
	| 'glat'
	| 'glong';

// Single point of telemetry data (one timestamp)
export interface TelemetryPoint {
	time: number;
	distance?: number;
	lat?: number;
	long?: number;
	speed?: number;
	rpm?: number;
	throttle?: number;
	brake?: number;
	gear?: number;
	steering?: number;
	glat?: number;
	glong?: number;
	[auxChannel: string]: number | undefined;
}

// All data for a single lap
export interface LapTelemetry {
	lapNumber: number;
	points: TelemetryPoint[];
}

// All telemetry for a session (what gets stored in one Parquet file)
export interface SessionTelemetry {
	sessionId: number;
	laps: LapTelemetry[];
	auxiliaryChannels: string[]; // Names of extra channels beyond standard
	metadata: {
		importedAt: string;
		sourceType: string; // 'vbo' | 'bosch' | 'merged'
		channelCount: number;
		totalPoints: number;
	};
}

// Storage interface (abstraction layer)
export interface TelemetryStorage {
	write(sessionId: number, data: SessionTelemetry): Promise<void>;
	read(sessionId: number): Promise<SessionTelemetry | null>;
	readLap(sessionId: number, lapNumber: number): Promise<LapTelemetry | null>;
	exists(sessionId: number): Promise<boolean>;
	delete(sessionId: number): Promise<void>;
}
```

**Verify:**

```bash
npx tsc --noEmit src/lib/server/telemetry/types.ts 2>&1 | head -5
```

**Done:**

- [ ] All types compile without errors
- [ ] Types are exported from the module
- [ ] Types cover standard channels + auxiliary channels from `telemetry_channels` table

---

## Task 3: Implement Parquet Write Module

**Type:** auto

**Files:** `src/lib/server/telemetry/parquet.ts`

**Action:**
Create the Parquet write/read module using apache-arrow. Implement the `TelemetryStorage` interface with efficient columnar storage.

**Implementation Requirements:**

1. **File Location**: `data/telemetry/{sessionId}.parquet`
2. **Schema Design**: Store as columnar format with these columns:
   - `lap_number` (Int32) - repeated per row
   - `time` (Float64)
   - `distance` (Float64, nullable)
   - `lat` (Float64, nullable)
   - `long` (Float64, nullable)
   - `speed` (Float64, nullable)
   - `rpm` (Float64, nullable)
   - `throttle` (Float64, nullable)
   - `brake` (Float64, nullable)
   - `gear` (Float64, nullable)
   - `steering` (Float64, nullable)
   - `glat` (Float64, nullable)
   - `glong` (Float64, nullable)
   - Plus any auxiliary channels (all Float64 nullable)

3. **Row Structure**: Each row is one timestamp sample across all channels
4. **Compression**: Use SNAPPY compression for balance of speed/size
5. **Metadata**: Store session metadata in Parquet file custom metadata

**Key Functions:**

```typescript
// Write entire session telemetry to Parquet file
export async function writeSessionTelemetry(
	sessionId: number,
	data: SessionTelemetry
): Promise<void>;

// Read entire session (for full load)
export async function readSessionTelemetry(sessionId: number): Promise<SessionTelemetry | null>;

// Read single lap (for efficient queries)
export async function readLapTelemetry(
	sessionId: number,
	lapNumber: number
): Promise<LapTelemetry | null>;

// Check if file exists
export async function telemetryExists(sessionId: number): Promise<boolean>;

// Delete telemetry file
export async function deleteTelemetry(sessionId: number): Promise<void>;
```

**Apache Arrow Implementation Notes:**

- Use `tableFromArrays()` to create Arrow Table from column arrays
- Use `writeParquet()` from apache-arrow for file writing
- For reading, use `parquetRead()` to get arrow table, then extract columns
- Convert columnar data back to the `SessionTelemetry` format

**Verify:**

```bash
# Check TypeScript compiles
npx tsc --noEmit src/lib/server/telemetry/parquet.ts 2>&1 | head -10

# Check no syntax errors
node --check src/lib/server/telemetry/parquet.ts 2>&1 | head -5
```

**Done:**

- [ ] All functions implemented with proper error handling
- [ ] File writes to `data/telemetry/{sessionId}.parquet`
- [ ] Creates `data/telemetry/` directory if it doesn't exist
- [ ] Metadata stored in Parquet file footer
- [ ] Returns proper TypeScript types from `types.ts`

---

## Task 4: Update Session Data Insert Function

**Type:** auto

**Files:** `src/lib/server/db/utils.ts`

**Action:**
Modify `insertSessionData()` to write telemetry to Parquet files instead of the `lap_telemetry` table. The function should:

1. Continue inserting lap records (metadata, times, validity) into `laps` table
2. Write telemetry data to Parquet file instead of `lap_telemetry` table
3. Keep the transaction for lap metadata, but write Parquet after transaction succeeds

**Changes Required:**

1. Import the new telemetry storage functions
2. Remove `lap_telemetry` and `telemetry_channels` inserts
3. Build `SessionTelemetry` structure from the incoming lap data
4. Call `writeSessionTelemetry()` after lap metadata is saved
5. Keep `telemetry_sources` inserts unchanged

**Code Structure:**

```typescript
import { writeSessionTelemetry, type SessionTelemetry, type LapTelemetry } from '$lib/server/telemetry/parquet';

export async function insertSessionData(
  sessionId: number,
  lapsToInsert: any[],
  sourceId: number,
  driverId: number | null
) {
  // 1. Stats for Outlier Detection (keep existing)
  // 2. Transaction for lap metadata only
  await db.transaction(async (tx) => {
    for (const lap of lapsToInsert) {
      // Insert lap record (metadata only)
      const lapResult = await tx.insert(laps).values({...}).returning({ id: laps.id });

      // NOTE: No longer inserting lap_telemetry here
      // NOTE: No longer inserting telemetry_channels here
    }
  });

  // 3. Build SessionTelemetry structure
  const sessionTelemetry: SessionTelemetry = {
    sessionId,
    laps: lapsToInsert.map(lap => ({
      lapNumber: lap.lapNumber,
      points: buildPointsFromArrays(lap.telemetry) // Convert arrays to points
    })),
    auxiliaryChannels: extractAuxiliaryChannels(lapsToInsert),
    metadata: {
      importedAt: new Date().toISOString(),
      sourceType: 'vbo', // or detect from metadata
      channelCount: countChannels(lapsToInsert),
      totalPoints: countTotalPoints(lapsToInsert)
    }
  };

  // 4. Write to Parquet
  await writeSessionTelemetry(sessionId, sessionTelemetry);
}
```

**Verify:**

```bash
# Check TypeScript compiles
npx tsc --noEmit src/lib/server/db/utils.ts 2>&1 | head -10
```

**Done:**

- [ ] `insertSessionData()` no longer writes to `lap_telemetry` table
- [ ] `insertSessionData()` no longer writes to `telemetry_channels` table
- [ ] Function calls `writeSessionTelemetry()` with properly structured data
- [ ] Lap metadata (times, validity) still inserted to `laps` table in transaction
- [ ] Function handles errors from Parquet write gracefully

---

## Verification Criteria

1. **Type Safety**: All TypeScript compiles without errors
2. **File Creation**: New imports create valid Parquet files in `data/telemetry/`
3. **Schema Correctness**: Parquet files contain all standard channels as columns
4. **Size Reduction**: Parquet files are 50%+ smaller than equivalent JSON array storage
5. **Integration**: Session save endpoint successfully writes to Parquet

---

## Success Criteria

- [ ] New telemetry imports write to `data/telemetry/{sessionId}.parquet`
- [ ] Parquet files are valid and readable by standard tools (e.g., `parquet-tools`)
- [ ] File sizes are 50%+ smaller than JSON array storage (measure with test data)
- [ ] All existing write paths use the new Parquet storage
- [ ] Lap metadata still properly saved to database
